# VR-video-lecture-notes
notes covering the entire course on 3D Virtual Environments and Animation (2018-19)

pdf, word and google docs is available in this repo (the google docs link is better)

<html><head><meta content="text/html; charset=UTF-8" http-equiv="content-type"></head>
  
<body class="c23"><div><p class="c2 c4"><span class="c1"></span></p></div><p class="c2"><span class="c19"><a class="c16" href="https://www.google.com/url?q=http://www.vrglossary.org/glossary&amp;sa=D&amp;ust=1554252556629000">http://www.vrglossary.org/glossary</a></span><span class="c19">&nbsp; </span><span class="c27">- </span><span class="c1">useful glossary</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c3">Week 1</span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">What is VR? </span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_mg5uvkv42ojs-0 start"><li class="c0 c6"><span class="c1">&nbsp;The experience in which the user is effectively immersed in a responsive virtual world</span></li><li class="c0 c6"><span class="c1">&nbsp;VR Implies that the user has dynamic control of their viewpoint (very important)</span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Why is VR different from other immersive media such as 3D cinema etc;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_a439gs3z4amj-0 start"><li class="c0 c6"><span class="c1">&nbsp;3D Stereovision (camera for each eye)</span></li><li class="c0 c6"><span class="c1">User dynamic control of viewpoint (display is updated to the viewpoint of one specific user, achieved via head tracking)</span></li><li class="c0 c6"><span class="c1">Surrounding experience (full visual perception is surrounded by the device - the more of your field of view is covered by your device - the more immersed you will be - size of screen does not matter, for example google cardboard)</span></li></ul><p class="c0"><span class="c1">(you are trapped, when you look around you still see images from the virtual world)</span></p><ul class="c9 lst-kix_u9yqzddpcyjy-0 start"><li class="c0 c6"><span class="c1">Experience is overwhelming and persistent - does not diminish over time.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Uses of VR:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Sport:</span><span class="c1">&nbsp;360-degree video - watch events from the best seat (not interactive) can choose seat. Used in theatre too.</span></p><p class="c2"><span class="c1">VR for sports training - Research papers show, training in the real world is still more effective. What you learn in VR, remains in VR. Skill are not yet transferable to the real world.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Illusion of being someone else:</span><span class="c1">&nbsp; need to give user a self-avatar where their actual body is.</span></p><p class="c2"><span class="c11 c7">Proprioception</span><span class="c20 c11">&nbsp;(or kinaesthesia) - someone&#39;s overall sense of their relative position of their own parts of their body. &nbsp;Warning, if the user moves, but the model stays in the same place, then the illusion will break. 360 video - person can&rsquo;t be changed. Important to have a static body where users expect their body to be. Mel Slater: VR can not only transform where you are, but who you are (useful in psychotherapy), we can choose someone else - long-lasting psychological effects on users.</span></p><p class="c2"><span class="c20 c11">&nbsp;</span></p><p class="c2"><span class="c7 c11">News &amp; Documentaries:</span><span class="c20 c11">&nbsp;Modal-based or 360-degree video can be used immerse the user in the news event - potential increase in empathy due to immersion.</span></p><p class="c2"><span class="c20 c11">&nbsp;</span></p><p class="c2"><span class="c11 c7">Scientific Data Visualisation:</span><span class="c20 c11">&nbsp;as opposed to information visualization, refers to the use of computer graphics for the analysis and representation of simulated or real data. Common feature of scientific data is that it highly dimensional, VR allows you to view and interact with data in 3D space. Useful for education and training. Help to fully comprehend 3-dimensional data. Could help doctors explain scan results to patients.</span></p><p class="c2"><span class="c11 c20">&nbsp;</span></p><p class="c2"><span class="c7">Medical Training:</span><span class="c1">&nbsp;used in immersive learning. 360 - video of surgery room. Surgical skill training, many problems - high end VR interaction devices. Can help Doctors improve their social skills, with challenging patients.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Physical Rehabilitation and Psychotherapy:</span><span class="c1">&nbsp;EEG example, paralysed patient imagines moving their avatar. Interactive visual feedback plays important role in motivation for patient. Makes rehabilitation- less painful and less boring. You can control the difficulty of the rehabilitation - progress in steps. Treatment in psychotherapy - can be used to treat phobias such as heights and spiders - risk free and controlled environment. Can help soldiers revisit traumatic events to stop them over-reacting PTSD.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Graphics:</span></p><p class="c2 c4"><span class="c1"></span></p><ul class="c9 lst-kix_jbt48gogz16k-0 start"><li class="c0 c6"><span class="c1">rendering: process of turning 3D representation into 2D images. (x, y, z) we only use points. Line get drawn between these points.</span></li><li class="c0 c6"><span class="c1">Vertices =&gt; Edges =&gt; Polygons (2D shapes) =&gt; Surfaces (meshes)</span></li><li class="c0 c6"><span class="c1">Skinned Mesh: Meshes that are rigged for animation</span></li><li class="c0 c6"><span class="c1">Polygons are simple, many polygons can create a curve</span></li><li class="c0 c6"><span class="c7">Photogrammetry</span><span class="c1">: taking many pictures of an object, digitising it into a 3D model.</span></li><li class="c0 c6"><span class="c1">Compound Objects = shared transforms, scale and move</span></li><li class="c0 c6"><span class="c1">In 3D graphics, we have a virtual camera that does a perspective transform which maps the object into 2d. In VR you need two cameras for each eye for 3D stereo vision. Camera needs to transform as head turns - main reason for VR experience.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">VR technical framework:</span></p><ul class="c9 lst-kix_x07s8rgqp5dj-0 start"><li class="c0 c6"><span class="c1">HMD, VR interaction, VR content (images to display or 360 video).</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Model based VR and 360 video:</span></p><ul class="c9 lst-kix_22gv36ir30ho-0 start"><li class="c0 c6"><span class="c1">360 video = video content generated in the real world</span></li><li class="c0 c6"><span class="c1">Analogue or digital cameras - highly realistic - fast capture but you cannot modify</span></li><li class="c0 c6"><span class="c7">Model Based = (CGI)</span><span class="c1">&nbsp;computer generated 3D content - longer to generate - easy to modify - you can reuse - go beyond real-life - interactive in real-time - can be photorealistic.</span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c10">Skipped brief history of VR</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Level of immersion in VR systems</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_1les0jaqcajt-0 start"><li class="c0 c6"><span class="c1">Ideal system: display in all sensory systems. Vision, Sound (undirected, spatialized sound, modelled, reflected in environment), Haptics (sense of touch, force feedback) and smell.</span></li><li class="c0 c6"><span class="c1">Haptics are currently specialized for certain application, no general haptic device. Currently no generalized smell, smell needs to linger or leave</span></li><li class="c0 c6"><span class="c1">Vision and sound are supported currently and particular/specialist haptics and sound exist today.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Measure immersion</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Immersion:</span><span class="c1">&nbsp;technical description of what a system can deliver (simulation on principal), technical specification (hardware and software) not the effect. If we take HMD A that can translate head, rotate with 6 degrees of freedom and another HMD B in which you can only rotate, you can say that HMD A is more immersive than HMD B, because you can use HMD A to simulate HMD B (HMD B is a subset of HMD A).</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Sensorimotor Contingency (SCs)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Definition:</span><span>&nbsp;part of a theory of active vision. Describes how we use our bodies to perceive. We have a set of implicit rules we use to perceive the world. By implicit we mean that they are rules we do not have to think about (for example to look around). Vision is not passive (not simply light entering our eyes - we actually move our heads, turn around etc ...) &nbsp;tactile feeling, reaching out your arms gives us a sense of distance for example. By sensorimotor contingency, that set of implicit rules whereby we use our bodies to perceive the world, across all the </span><span>different</span><span class="c1">&nbsp;senses.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>&ldquo;</span><span class="c28">sensorimotor contingencies (SCs) refer to the actions that we know to carry out in order to perceive&rdquo; - Mel Slater</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Sensorimotor Contingency (SCs) in VR</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_2xurrzjcnzlo-0 start"><li class="c0 c6"><span class="c7">Immersion:</span><span class="c1">&nbsp;the affordances the system gives you. More importantly, what does the system give you in terms of perception. Combination of how you perceive and what you perceive. The more that the How matches reality and the more what you perceive &nbsp;matches what you expect to see in reality through the act of perception. &nbsp;So you&#39;re getting closer to an actual sense of SCs. Brain beleives thar VR is real through natural SCs.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c1"></span></p><p class="c2 c4"><span class="c1"></span></p><p class="c2"><span class="c5">Why do we need Immersive VR ?</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_gjyqt58fmt4g-0 start"><li class="c0 c6"><span class="c7">You don&rsquo;t </span><span class="c12">- it depends on what you want to do</span><span class="c1">. VR, gives you presence. Useful in clinical psychology. Treating fear of heights- gradual exposure to what they fear does work. Showing a movie of heights does not work, putting someone in a VR virtual height - same level of real height is induced. The immersion leads to an illusion of presence. &nbsp;Brain does not know about VR, has to make a very fast decision. We are not in charge of all our reactions and actions. (Virtual height example)</span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">VR challenges</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_6cn97j6ep6rn-0 start"><li class="c0 c6"><span class="c7">Realism (Graphics) :</span><span class="c1">&nbsp;In training and therapy if the graphics do not reflect the real world (photo-realistic), then skills acquired in VR won&rsquo;t be transferable. &nbsp;In order to create photo-realistic environments, you need to know how lighting works in real life. </span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_7kbin0prxevx-0 start"><li class="c0 c6"><span class="c7">Diffuse:</span><span class="c1">&nbsp;even looking reflection - reflects light equally in all directions, less computationally expensive.</span></li></ul><p class="c0 c4"><span class="c1"></span></p><ul class="c9 lst-kix_hrhjezn4trt8-0 start"><li class="c0 c6"><span class="c7">specular surface (metal):</span><span class="c1">&nbsp;lights are reflected in a certain direction, giving it the shine look, more computationally expensive. Glossy and mirror surfaces are the most expensive.</span></li><li class="c0 c6"><span class="c7">Local illumination:</span><span class="c1">&nbsp;consider only lights that come directly from the light source.</span></li><li class="c0 c6"><span class="c7">Global illumination:</span><span class="c1">&nbsp; inter-reflection between objects, like real life.</span></li><li class="c0 c6"><span class="c7">360 video:</span><span class="c1">&nbsp;you cannot change lighting.</span></li><li class="c0 c6"><span class="c7">Realism (animations)</span><span class="c1">: Humans are critical observers of animation, any slight mistake will be noticed.</span></li><li class="c0 c6"><span class="c7">Navigation:</span><span class="c1">&nbsp;position tracking - allows you to move your body- viewpoint will change. Mobile VR you can only rotate your head. Physical navigation problem - you are limited by the amount of physical space you have, does not work with mobile VR. Moving with a joystick can make you sick (nausea).</span></li><li class="c0 c6"><span class="c1">360 video, fixed position where you filmed but google street-view you can navigate.</span></li><li class="c0 c6"><span class="c1">You can walk in space, does not cause nausea but no sense of acceleration.</span></li><li class="c0 c6"><span class="c1">Teleporting can reduce nausea too, but user can be disoriented when teleporting to a new location.</span></li><li class="c0 c6"><span class="c1">3D navigation that relies on interfaces (such as the keyboard) is not encouraged.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2"><span class="c5">Nausea (simulation sickness)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_bnde37npd5ij-0 start"><li class="c0 c6"><span class="c1">Discomfort induced by simulated environments</span></li><li class="c0 c6"><span class="c1">Mainly caused by the conflict between information received in the brain from our vestibular system and our visual system.</span></li><li class="c0 c6"><span class="c1">In this situation, you are physically moving but are looking at someone that is relatively &nbsp;still. The vestibular system tells the brain that you are moving, but the visual system says that you are not =&gt; feeling sick</span></li><li class="c0 c6"><span class="c1">Simulation sickness is opposite to this. Vestibular: you are not physically moving but your visual system says you are (immersed in VR) = causes nausea.</span></li><li class="c0 c6"><span class="c1">Best way to avoid this, physical movements similar to real life cause less nausea, walk-in place and teleporting also reduce nausea.</span></li><li class="c0 c6"><span class="c1">&nbsp;Worst method is to use the default 1st person camera (keyboard, mouse joystick) =&gt; causes sickness.</span></li><li class="c0 c6"><span class="c1">Eye strain, as displays are close to eyes</span></li><li class="c0 c6"><span class="c1">Frame rates below 90fps</span></li><li class="c0 c6"><span class="c1">Flashing and High-Contrast images</span></li><li class="c0 c6"><span class="c1">Some people are less prone to simulation sickness.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>&nbsp;</span><span class="c5">Meeting other people:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">In person we are better at negotiation than in video conferencing.</span></p><p class="c2 c18"><span class="c1">- &nbsp; &nbsp; &nbsp; &nbsp;Relationship building</span></p><p class="c2 c18"><span class="c1">- &nbsp; &nbsp; &nbsp; &nbsp;Trust</span></p><p class="c2 c18"><span class="c1">- &nbsp; &nbsp; &nbsp; &nbsp;Body language</span></p><p class="c2 c18"><span class="c1">- &nbsp; &nbsp; &nbsp; &nbsp;Facial expressions</span></p><p class="c2 c18"><span class="c1">- &nbsp; &nbsp; &nbsp; &nbsp;Timing</span></p><p class="c2 c24"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_42j6e8msbfae-0 start"><li class="c0 c6"><span class="c1">We rely on social skills acquired over years that operate on the unconscious level.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_lpmp21x3g9hu-0 start"><li class="c0 c6"><span class="c1">Facial expression is hard to track due to HMD covering face.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_ghlmbvd8yyxm-0 start"><li class="c0 c6"><span class="c1">Eye gaze, pupil dilation, Subtle emotion changes: blushing, sweating, Subtle facial muscle movements all need to be tracked for realism.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Volumetric capturing can work but it relies on post-processing, it is not real-time.</span></p><p class="c2"><span class="c1">Current tech does not support meaningful physical contact with another person (cannot shake someone hands etc...)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2"><span class="c5">Haptic feedback</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_cl3dd6q2ipag-0 start"><li class="c0 c6"><span class="c1">Ability to interact with objects in a naturalistic way is still poor with current technology. We need VR gloves, good tracking but no haptic or tactile feedback. Exoskeleton gloves provides haptic feedback. Force and tactile feedback still available with VR suits.</span></li></ul><p class="c25"><span class="c1">&nbsp;</span></p><p class="c25"><span class="c5">What is the difference between tactile feedback and haptic feedback?</span></p><p class="c2"><span class="c1">Tactile Feedback is a type of Haptic Feedback. Haptic feedback is generally divided into two different classes: Tactile and Kinaesthetic. The difference between the two is quite complex, but at a high level:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_4ulr50383qoq-0 start"><li class="c0 c6"><span>&nbsp;</span><span class="c7">Kinaesthetic:</span><span class="c1">&nbsp;The things you feel from sensors in your muscles, joints, tendons. Weight, stretch, joint angles of your arm, hand, wrist, fingers, etc. Imagine holding a coffee-mug &nbsp;in your hand. Kinaesthetic feedback tells your brain the approximate size of the mug, it&#39;s weight, and how you are holding it relative to your body.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_i1vn6kahcpue-0 start"><li class="c0 c6"><span class="c7">Tactile:</span><span class="c1">&nbsp;The things you feel in your &#39;fingers&#39; etc., or on the surface. The tissue (for example in your fingers), has a number of different sensors embedded in the skin and right underneath it. They allow your brain to feel things such as vibration, pressure, touch, texture etc.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Haptic Feedback is a combination of both Tactile and Kinaesthetic Feedback.</span></p><p class="c2"><span class="c14"><a class="c16" href="https://www.google.com/url?q=https://www.quora.com/Robotics-What-is-the-difference-between-tactile-feedback-and-haptic-feedback&amp;sa=D&amp;ust=1554252556642000">https://www.quora.com/Robotics-What-is-the-difference-between-tactile-feedback-and-haptic-feedback</a></span></p><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c10">Skipped history of VR</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2"><span class="c3">Week 2: VR Graphics</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">We see objects through the light that is reflected off them. Real objects have many details, colour, rough, smooth - properties of the surface of the object. How light reflects of the surface fundamentally shapes what it would look like - refer to this as material.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c10">Skipped most videos this week, a lot of it is not theory just practical, less likely to come up in the exam.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Two cameras must render the same scene, post-processing is required. For VR to work when you move your head the frames need to update fast.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Motion to Photon time:</span><span class="c1">&nbsp;From the moment the you move your head through to the moment the image is rendered. Needs to be less than 20ms. Lot of processing in a short amount of time - high end PCs are required.</span></p><p class="c2"><span class="c7">Global illumination</span><span class="c1">: very expensive, natural light that bounces off other objects. Global illumination can be baked(pre-computed) before rendering, works well with static objects.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Ambient lighting</span><span class="c1">: very cheap</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">What&rsquo;s the difference between Graphics in VR and games &amp; films?</span></p><ul class="c9 lst-kix_cs5qx82jesgu-0 start"><li class="c0 c6"><span class="c1">Same graphic techniques that is used in games (both real-time)</span></li><li class="c0 c6"><span class="c1">Animations and films are not real-time</span></li><li class="c0 c6"><span class="c1">&nbsp;VR is more computationally intensive</span></li><li class="c0 c6"><span class="c1">Presence and comfort more important in VR</span></li><li class="c0 c6"><span class="c1">Rendering two screens at under 20ms - limited by what you can do.</span></li><li class="c0 c6"><span class="c1">Bump mapping (creates effect of &ldquo;bumbs&rdquo;) on surface, does not work in VR</span></li><li class="c0 c6"><span class="c1">Parallax mapping works better</span></li><li class="c0 c6"><span class="c1">Place illusion, plausibility illusion and embodiment illusion together these form presence</span></li><li class="c0 c6"><span class="c1">Graphics can support or fail to support place and plausibility</span></li><li class="c0 c6"><span class="c1">Better graphics does not improve presence, graphics did not make a big difference.</span></li><li class="c0 c6"><span class="c1">However, some techniques work well such as real-time shadows.</span></li><li class="c0 c6"><span class="c1">High frequency movement can cause nausea. Aliasing - seeing the pixels of object can be disturbing, anti-aliasing can avoid this.</span></li><li class="c0 c6"><span class="c1">VR is like the real-world, you should use the real-world as your reference.</span></li><li class="c0 c6"><span class="c1">VR scale is more noticeable than in games. Sensitive to even small inconsistencies</span></li><li class="c0 c6"><span class="c1">&nbsp;In VR, environments need to be a size that you can comfortably move around in, unlike in games in which you move at 30mph.</span></li><li class="c0 c6"><span class="c1">VR, there is no frame, you can look around everywhere, you can&#39;t control the users but you can guide them. Do not make assumptions, keep testing in VR - you need to check if the environment you have made works.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">The Three illusions of VR</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_1pn2wpo4hms0-0 start"><li class="c0 c6"><span class="c21 c7">Place illusion:</span><span class="c1">&nbsp;a feeling of being in a virtual place even though you know that you are not there. When you have visual sensorimotor contingencies that more or less like real life, this affords the possibility for the brain to make a decision that this is where I am, the virtual place rather than the real place.</span></li></ul><p class="c0"><span class="c7">Place illusion</span><span class="c1">: can occur if nothing else is happening in the environment, as long as you can look around.</span></p><ul class="c9 lst-kix_xxv6kuvk7rz7-0 start"><li class="c0 c6"><span class="c21 c7">Plausibility illusion:</span><span class="c1">&nbsp;how real do I take the events around me to be. It is separate from place illusion. For example if you are driving a car and you see a policeman from a distance you begin slow down, but as get closer, you see that the policeman is actually a cardboard cutout - plausibility breaks, you know it is not a real policeman. Plausibility: The events that I am perceiving are really happening.</span></li><li class="c0 c6"><span class="c7 c21">Embodiment:</span><span class="c1">&nbsp;sensorimotor contingency in the real world when I look down I see my body. In VR, &nbsp;If you look down and see a virtual body = embodiment illusion (body ownership) form and shape of body can be quite powerful.</span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span>Place illusion</span><span class="c7">&nbsp;</span><span class="c1">Examples: public speaking VR, the Bystander problem&hellip;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Does immersion cause Place Illusion (PI)?:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_zdx3uc7bkefd-0 start"><li class="c0 c6"><span class="c7">Immersion </span><span>= what the system offers, the technology. </span><span class="c7">PI </span><span>= response of the individual. Immersion provides a framework basis in which place illusion can occur. Immersion </span><span class="c7">does not</span><span class="c1">&nbsp;cause place illusion, it&#39;s on the basis on which PI can arise. (different people can respond differently in the same VR world)</span></li></ul><p class="c2"><span>&nbsp;</span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2"><span class="c3">Week 3</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Interaction in VR is completely different than in other media.</span></p><p class="c2"><span class="c1">You have an HMD covering your face - you can&rsquo;t see the interaction devices in the virtual world. You can&rsquo;t see the keyboard. Mouse and touchscreen is mostly designed for 2D interfaces, you can&rsquo;t interact with depth.</span></p><p class="c2"><span class="c1">VR is all about creating the three illusions that make up presence.</span></p><p class="c2"><span class="c1">Embodiment is about linking your body to the interaction, by visual representation of your body as well as physically moving your body.</span></p><p class="c2"><span class="c1">Computer interface are based on metaphors - for example the desktop.</span></p><p class="c2"><span class="c1">When developing in VR you should think about how you interact with the real world.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Natural Interaction:</span></p><p class="c2"><span class="c1">Allows us to use the same skills used in real life and apply them in the virtual world. You don&rsquo;t have to know about tennis to play Wii tennis.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Interface need to show you what you can do and give you feedback when you carry out an action. Gestural interfaces do not do any of these things, you don&rsquo;t know which gestures you need to do - hard for software to recognise. VR interaction should be close to the real world, but there needs to be feedback, gestures need to be clear.</span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">Magic Interaction:</span></p><p class="c2"><span class="c1">Interaction should be realistic as possible, close to the real world. Because VR is not the real world you can do things you can&rsquo;t do in the real world - magical interaction, like reaching out to grab an item, magical interfaces can be better than natural interaction, you shouldn&rsquo;t limit yourself to real world interactions.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Active and passive interaction:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Active interaction</span><span class="c1">&nbsp;- consciously deciding to interact, like using a mouse to click on an icon.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Passive interaction </span><span class="c1">- not consciously interacting. Not doing anything, detecting what you&rsquo;re doing and reacting, for example a fitness tracker. Unlikely to be aware.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Turning your head to look around in VR is a passive interaction. You don&rsquo;t have to think about turning around, HMD responds to you. </span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Passive interaction can be bad/creepy - software collecting data on you. Not clear how it works for the user. Use passive interaction for indirect things.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Affordances:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Interaction design. Affordance is the relationship of an object and our ability to act on it. For example, a door handle (object) = pulling with our hand (ability to act on it). Affordances are not always designed. Affordances in VR are closer to the real world. Affordances depend on the properties of an object and your ability to act. False affordances = bad design, pull on a door handle that you must push. Make sure you have good signalling of affordances.</span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">VR interaction theory:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">All interaction should be based on the real world - not in games or films. Interaction must be useable - make it clear how the user should interact with the world. Design your objects so that the actions you can carry out on the object are obvious. We can see what actions we can do to an object just by looking at it (affordances). A well-designed object has clear affordances. Keep testing with different people.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>&nbsp;</span><span class="c5">Introduction to Plausibility Illusion</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Bystander situation is an example. If an aggressor does not respond to you shouting or if the characters ignore you then this is a failure of plausibility. Bar example in video - animations were repetitive, users noticed this.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Necessary conditions for Psi (Place Illusion &amp; Plausibility Illusion)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_ku9qtx94wj8x-0 start"><li class="c0 c6"><span class="c7">Events</span><span>&nbsp;occur in relation to </span><span class="c12">you</span><span class="c1">&nbsp;personally, the subject of an action by another part of the visual environment.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_n160o68uzbf4-0 start"><li class="c0 c6"><span class="c7">World</span><span class="c1">&nbsp;responds to you, you walk through a crowd - the crowd moves out of the way.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_y5brltwawns2-0 start"><li class="c0 c6"><span class="c7">Credibility</span><span class="c1">, environment needs to respond to people&#39;s expectation - If you are depicting something in reality than it should conform to that. We don&#39;t know how the credibility part of plausibility works.</span></li></ul><p class="c2"><span class="c1">&nbsp; </span></p><p class="c2"><span class="c5">Break of presence:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Because place illusion is perceptual and because it relies on the Sensorimotor-contingency, sensorimotor-contingency is provided by the system/immersion, they don&rsquo;t change. When place illusion breaks it comes back again.</span></p><p class="c2"><span class="c1">&nbsp; &nbsp; &nbsp; &nbsp; &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;</span></p><p class="c2"><span class="c1">When plausibility breaks it never comes back again, because Plausibility is more cognitive and place illusion is more perceptual.</span></p><p class="c2"><span>&nbsp;</span></p><p class="c2"><span class="c3">Week 4</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">HMD</span><span class="c1">&nbsp;= User Input</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Inputs:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">HR</span><span class="c1">&nbsp;= Head Rotation (3 degrees of Freedom- does not update when we move our head sideways)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">HP</span><span class="c1">&nbsp;= Head Position (you look forward, sideways, move around - 6 degrees of freedom)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">CR</span><span class="c1">&nbsp;= Controller Rotation</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">CP</span><span class="c1">&nbsp;= Controller Position</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>VR interaction is supposed to be cognitively</span><span class="c12">&nbsp;less</span><span class="c1">&nbsp;demanding.</span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2"><span class="c5">Navigation in VR:</span></p><p class="c2"><span class="c1">High-end VR with precision tracking supports physical navigation. </span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Room-scale VR (Physical Navigation)</span><span class="c1">&nbsp;is the most natural form of movement, physical motion powerfully aids illusion of presence, actual walking allows you to feel how large a place is. Less likely to cause simulation sickness. Limitation of physical space. Health &amp; Safety issues. Require user to state how much physical space they have. We use the same body, as we do in real life.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Redirected walking</span><span class="c1">&nbsp;manipulates users into believing that they are walking on a straight line, whereas in the physical reality they are walking in a curved line. Causes users to change their direction of walking without them noticing. Walk around a circle thinking they are walking on straight line. The angle of rotation should be a function of the users velocity, so if the users moves faster, the world rotates quicker. Angular velocity, when the user turns around, we can make Virtual world turn to one direction, resulting in them actually turning bigger or smaller angle in the physical world than in the virtual world. A combination of adding rotation distortion, using both linear and angular rotation could quite dramatically increase the perception of the physical space available. Requires a lot of programming and creativity.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Walk-in-Place- Navigation in VR by engaging fully body movement without moving forward. Head tracker position will dictate position </span></p><p class="c2"><span class="c5">&nbsp;</span></p><p class="c2"><span class="c5">Virtual Navigation:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Using a joystick to move just like in games can cause nausea. In real life, you would mostly be looking at the direction of travelling. Secondly, too many changes in speed and acceleration can also cause nausea. You need to give users control of their speed.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Teleporting:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Target location = the new place users wish to travel to. &nbsp;All methods discussed previously only apply to model-based VR (what we did with unity).</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Travel in VR - Quality Factors</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_96s714fof93-0 start"><li class="c0 c6"><span class="c7">Speed:</span><span class="c1">&nbsp;how much control does the user have in terms of speed? Sense of control, not actual control. Constant speed is better for the user instead of a there being constant speed changes.</span></li><li class="c0 c6"><span class="c7">Accuracy</span><span class="c1">: Is the user able to arrive at the desired target? How likely is the user to overshoot the target?</span></li><li class="c0 c6"><span class="c7">Spatial awareness</span><span class="c1">: the users implicit knowledge of their position and orientation within the environment during and after travel. Does the user feel disorientated after travel? do they have a good sense of scale? after exploring the VR scenario can they draw an accurate map of the virtual world they visited?</span></li><li class="c0 c6"><span class="c7">Ease of Learning</span><span class="c1">: Is this something easy for a novice user to use? How long would it take on average for the user to get a hand on it? cognitive load?</span></li><li class="c0 c6"><span class="c7">Information gathering:</span><span class="c1">&nbsp;the users ability to actively obtain information from the environment during their travel. After their experience can they remember objects they saw?</span></li><li class="c0 c6"><span class="c1">How comfortable is the experience for the user?</span></li></ul><p class="c0"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c3">Week 5</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Best VR experiences use techniques from games, films and immersive theatre. The Three illusions are key for VR experiences. Plausibility is the most important in terms of interaction. You need to maintain plausibility. VR is about simulating reality, you are trying to get user to use their body and brain in the same way they do in real life, doesn&rsquo;t matter if the experience is fantasy or abstract, you still need to understand as human beings, how we interpret external signals and internalise using our body and mind. We can beyond real life. Avoid 2D menus. User comfort is important, no one wants to stay in experience if it makes them sick.</span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2"><span class="c5">User Evaluation:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">User testing takes a long time, data analysis is required. A/B testing. Quantitative data- numbers, measurements, 1 to 5 scale - objective data - allows comparisons. Qualitative data, subjective, opinion based, useful for measuring plausibility. Film user testing.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Testing is useful to decide which feature to keep or change in a game.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">The Pinocchio Illusion: watch the video</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_y3ytlu36t3dq-0 start"><li class="c0 c6"><span class="c1">Brain has a contradiction to resolve, the brain doesn&rsquo;t like contradiction it likes solutions, it believes its nose is that long.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">The Rubber Hand Illusion:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_l0qpxralxl3t-0 start"><li class="c0 c6"><span class="c1">Brain can quickly give you an illusion that its body has changed.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Psychological Effects of Embodiment Illusion:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_txxrz764z1iv-0 start"><li class="c0 c6"><span class="c1">Brain doesn&rsquo;t actually have access to knowing what&#39;s part of our bodies, it can only rely on the signals it receives.</span></li><li class="c0 c6"><span class="c1">Vision overrides other sense, such as proprioception (where your hand is in space)</span></li><li class="c0 c6"><span class="c1">VR allows opportunities not possible in the real world, like a virtual body part.</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c5"></span></p><p class="c2"><span class="c5">Visual-Tactile and Visual-Motor Synchrony</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Rubber-hand (the Visual-tactile synchrony) experiment in VR had the same results as the same experiment in real life. In VR you can go beyond the rubber hand, virtual arm could be programmed for different movements.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Visual-tactile synchrony</span><span class="c1">&nbsp;- the virtual hand moving caused increases electrical activity in the real arm - dependent on the subjective strength of the illusion. The stronger the illusion, the more electrical activity.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Visuo-motor synchrony: </span><span class="c7 c13">&nbsp;</span></p><p class="c2"><span class="c1">visual motor is when you move your body and you see the virtual body move synchronously, it&#39;s simply the fact of looking down and seeing a body, substitute your own body is already enough to give you the illusion</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c12">&ldquo;The vast amount of research on the</span><span class="c19 c12"><a class="c16" href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DTCQbygjG0RU&amp;sa=D&amp;ust=1554252556655000">&nbsp;rubber hand illusion</a></span><span class="c10">&nbsp;uses visuotactile synchronous stimulation to induce the illusion. This means that sight of the rubber hand being touched is synchronous temporally and spatially with the tactile stimulation felt on the corresponding (hidden) real hand. (seeing the hand)</span></p><p class="c2"><span class="c10">&nbsp;</span></p><p class="c2"><span class="c12">It has also been shown that</span><span class="c12"><a class="c16" href="https://www.google.com/url?q=http://www.plosone.org/article/info%253Adoi%252F10.1371%252Fjournal.pone.0010381&amp;sa=D&amp;ust=1554252556656000">&nbsp;</a></span><span class="c12 c19"><a class="c16" href="https://www.google.com/url?q=http://www.plosone.org/article/info%253Adoi%252F10.1371%252Fjournal.pone.0010381&amp;sa=D&amp;ust=1554252556656000">the illusion can be induced with visuomotor stimulation</a></span><span class="c12">&nbsp;- meaning that (in this case) the virtual hand moves synchronously with the movements of the corresponding (hidden) real hand. (moving the Hand)&rdquo; </span><span class="c1">mel slaters blog</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">We know that we are in this world, because we can see our bodies.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>Technical setup:</span><span><a class="c16" href="https://www.google.com/url?q=http://journal.frontiersin.org/article/10.3389/frobt.2014.00009/full&amp;sa=D&amp;ust=1554252556657000">&nbsp;</a></span><span class="c17"><a class="c16" href="https://www.google.com/url?q=http://journal.frontiersin.org/article/10.3389/frobt.2014.00009/full&amp;sa=D&amp;ust=1554252556657000">http://journal.frontiersin.org/article/10.3389/frobt.2014.00009/full</a></span></p><ul class="c9 lst-kix_21mv77nsm3fb-0 start"><li class="c0 c6"><span class="c1">Wide field of display</span></li><li class="c0 c6"><span class="c1">tracked HMD</span></li><li class="c0 c6"><span class="c1">Head tracked using a body tracker</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Change in Attitude, Behaviour and Cognition: (main reason VR is being pushed)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Change of the body in VR altered the participants perception. Empathy. Racial bias. Unconscious mimicry. Behaviour changed subconsciously.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c8">https://pure.royalholloway.ac.uk/portal/files/26296788/Maister_et_al_TICS_authors_version_Figures.pdf</span></p><p class="c2"><span class="c8">&nbsp;</span></p><p class="c2"><span class="c1">Self-counselling and treating depression:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">You can give better advice to a friend than to yourself. </span></p><p class="c2"><span class="c17"><a class="c16" href="https://www.google.com/url?q=http://bjpo.rcpsych.org/content/2/1/74&amp;sa=D&amp;ust=1554252556658000">http://bjpo.rcpsych.org/content/2/1/74</a></span></p><p class="c2"><span class="c17"><a class="c16" href="https://www.google.com/url?q=https://www.nature.com/articles/srep13899&amp;sa=D&amp;ust=1554252556658000">https://www.nature.com/articles/srep13899.</a></span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Comparing CGI and 360 Video</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Embodiment illusion works best with modal based VR. 360 Video: problems with position of body. Good to capture large spaces, things that are far away. 360 video does not provide a sense that you were in that place, with video you know its video - it&rsquo;s not real, it can&#39;t interact with you.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c26">This is where Prof Mel Slater&#39;s theory on the three illusions was first published:</span></p><p class="c2"><span class="c17"><a class="c16" href="https://www.google.com/url?q=https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2781884/&amp;sa=D&amp;ust=1554252556659000">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC2781884/</a></span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Embodiment is the most important aspect of VR, it is completely unique.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Physics Interaction:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_6imehxc7bwuf-0 start"><li class="c0 c6"><span class="c7">Physics</span><span class="c1">&nbsp;(programmed, objects respond to force)(great for dynamic animation like balls works well for non-complex objects - infinite responses)</span></li></ul><p class="c0 c4"><span class="c1"></span></p><ul class="c9 lst-kix_6imehxc7bwuf-0"><li class="c0 c6"><span class="c7">Key-Frame animation </span><span class="c1">(hand animation, not very interactive, play animation clips depending on what the user does - state machines)(more complex movements but only allows a small number of responses)</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c3">Week 6</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Our ability to interact with objects in the virtual world is essential for creating the plausibility illusion in VR. Direct control or agent control. Positioning of an object. Rotation, change orientation of an object. User could change scale too.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">DoF</span><span class="c1">&nbsp;(Degrees of Freedom)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Position</span><span class="c1">: 3 degree of freedom:</span></p><ul class="c9 lst-kix_yg7mchcn1tse-0 start"><li class="c0 c6"><span class="c1">&nbsp;X, Y and Z axis rotation</span></li></ul><p class="c2"><span class="c7">Rotation:</span><span class="c1">&nbsp;3 degree of freedom:</span></p><ul class="c9 lst-kix_1vjgfr8ibif-0 start"><li class="c0 c6"><span class="c1">&nbsp;Pitch (moving up and down), Roll (sideways) and Yaw (left - right)</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Position and Rotation: 6 degree of freedom</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Immersive systems need to provide to user this framework:</span></p><ul class="c9 lst-kix_a5gjzzldc8w9-0 start"><li class="c0 c6"><span class="c1">Indication of object</span></li><li class="c0 c6"><span class="c1">Confirmation of selection</span></li><li class="c0 c6"><span class="c1">Feedback</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Object interaction within reach of real arm, this is what people naturally do in real life. Important for;</span></p><ul class="c9 lst-kix_xaydkt8ytokh-0 start"><li class="c0 c6"><span class="c1">&nbsp;Physical rehabilitation</span></li><li class="c0 c6"><span class="c1">Training and therapy</span></li><li class="c0 c6"><span class="c1">Sports games</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">The most naturalistic way to represent object interaction in VR is to use a simplistic virtual hand. Low cognitive load, anyone can do it. You do not want your hand to be gender, age specific.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Problems:</span><span class="c1">&nbsp;users can only interact with objects within reach without having to travel. Frustration can occur when they cannot interact with certain items, problems with clipping - you cannot stop your hand from dragging an item through a table - can break plausibility illusion.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Hyper-natural interaction:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Interacting with objects beyond our arm length. Go-Go technique allows virtual arm to be longer than the real arm.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Magic Interaction:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Recasting a virtual pointer. Reach objects out of reach, not something we do in real life. Natural and Hyper-natural is better, magic interaction can break plausibility. You can do a hybrid approach of both natural and magic interaction. Occlusion framing. Eye- hand visibility mismatch. You can scale down the word, and move around in it.</span></p><p class="c2 c4"><span class="c1"></span></p><p class="c2"><span class="c5">Evaluation metrics:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_h9a0gj9e67yd-0 start"><li class="c0 c6"><span class="c7">Task performance</span><span class="c1">: how long does it take for a user to perform a task and how accurate are they at performing it?</span></li><li class="c0 c6"><span class="c7">Usability related issues</span><span class="c1">: how easy it uses the techniques, is it cognitively demanding?</span></li><li class="c0 c6"><span>How </span><span class="c7">natural</span><span>&nbsp;and </span><span class="c7">immersive</span><span class="c1">&nbsp;the experience is.</span></li><li class="c0 c6"><span class="c7">Expressiveness</span><span class="c1">: flexibility user has with a given technique</span></li><li class="c0 c6"><span class="c7">User comfort</span><span class="c1">, does the user suffer from simulation sickness or tiredness</span></li></ul><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">In application such as simulation and training you need the interaction to be as realistic as possible, so the users can apply their skills to the real world.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">If developing a game, ease of learning is important to get as many people as possible involved.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">If you are developing a tool for experts, for example a data visualization tool for neuroscientists to visualise MRI data. It needs to unsophisticated enough that once they have learned the interaction it engages fairly low cognitive load, so they can use it as a tool to solve more cognitively demanding tasks.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c10">Week 7 - no video lectures</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c3">Week 8</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Introduction to Social VR and characters:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Verbal (speech) </span><span>and </span><span class="c7">non-verbal (body language)</span><span class="c1">&nbsp;signals. Emoticons were designed to express non-verbal signals such as emotions. Online communication often over-simplifies or removes real-time social signal exchanges. VR is normally between real and digital social interaction, can combine both.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Virtual characters:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Photorealistic and cartoon like characters. Anthropomorphic, non-humans having human features. Visual fidelity how real does a character look. Motion fidelity, more important, how does a character move. Avoid high visual fidelity and low motion fidelity. The visual fidelity sets the expectation.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Agents and Avatars:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">PC (player character or player) directly controlled, also called avatars. Agents (NPC) cannot be controlled but the player can interact with, NPC are controlled by algorithms.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Applications of Virtual Characters:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">In VR we interact with virtual characters.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Introduction to character animation:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Unlike other animated objects, humans are very attuned to human animations, we can easily notice any mistakes or poor quality in human animations.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Two basic ways to animate characters for VR:</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_ewmjelkjojiy-0 start"><li class="c0 c6"><span class="c5">Pre-recorded animations:</span></li></ul><p class="c2"><span class="c1">Sequences of poses of a character that can be played back to create movement. Hand animation using keyframe animations or recorded from a real person using motion capture. This type of animation is not flexible, cannot be adapted to the moment, uses state machines. Can achieve complex movements.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><ul class="c9 lst-kix_xxcqpy3xgvy4-0 start"><li class="c0 c6"><span class="c5">Procedural simulations:</span></li></ul><p class="c2"><span class="c1">Generating movement in real-time using code, such as eye-ball movement.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Most Body language is subconscious it&rsquo;s not directly controlled by the person.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span>Uncanny Valley: </span><span class="c8">https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4428060/</span></p><p class="c2"><span class="c8">&nbsp;</span></p><p class="c2"><span class="c1">Human conversation is highly complex, body language, speech, tone, personal space, posture etc &hellip;</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">FK</span><span class="c1">&nbsp;= Forward kinematics takes longer to animates (for example, to move hand you first move arm =&gt; forearm =&gt; wrist =&gt; hand)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">IK</span><span class="c1">&nbsp;= Inverse kinematics (algorithm, much quicker to animate, you move hand - algorithm handles the rest)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c15">Mocap is much faster, requires no artistic skills.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Facial expressions - we need to animate face and head movement.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Facial Action Coding System (FACS)</span><span class="c1">&nbsp;- based on minimal facial movements we can make called action units</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Facial bones is used to animate the face. Harder for animators. Animators normally use blend shapes (a complete copy of the face mesh with a different facial expression, animations are created by combining face meshes to form new expressions based on FACS)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Visemes</span><span class="c1">&nbsp;- mouth shapes, the visual versions of the basic sounds (phonemes)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Importance of gaze in social interaction, eye contact shows that we are paying attention to someone, can indicate a range of social meanings, from intimacy to aggression. &nbsp;We use eyes in very complex ways, not just for vision. Most part in VR we are controlling whether the character is looking at the player or not. Eyes are normally procedurally animated using inverse kinematics.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Blushing is easier with virtual characters, but not with humans - happens subconsciously (even the best actors cannot make themselves blush). The effect on participants happens on a subconscious level (try adding pale, gaze, small facial expressions to a virtual character) </span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2 c4"><span class="c3"></span></p><p class="c2"><span class="c3">Week 9</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Abstract interfaces:</span><span class="c1">&nbsp;we can try to keep the interaction, body based and use gestures to interact, can be tiring and hard to remember.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">GUI are touchscreen interfaces in VR, real world is full of GUI, so it will probably feel natural to the user.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Diegetic and non-diegetic UI</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c7">Non-diegetic interface</span><span class="c1">: like health bars in games, not part of the game world- overlaid onto the screen. Works best in screen-based games.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c5">Diegetic interface:</span></p><p class="c2"><span class="c1">Appears in the VR world, attached to objects or floating. Also known as spatial UI. On-body UI.</span></p><p class="c2"><span class="c5">Gesture Interaction:</span></p><p class="c2"><span class="c1">More likely to feel natural, if they are close to real world actions, easier to learn. Hard to implement, remember some cultures gestures have different meaning (nodding your head means yes in the west, but in some cultures, it may mean something else)</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">VR needs diegetic interfaces. UI can become pixelated, harder to read, small text won&rsquo;t work. VR controllers are great for 3D interaction but not for complex detailed interaction. UI should be simple and big. UI in VR does not have a physical surface, needs to a have wide tolerance for interacting. UI should not be transparent, otherwise the user keeps staring at objects nearby and far away will cause and headache. Curved interfaces are better than flat interfaces.</span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c1">Without testing the VR app, you are going to make the wrong assumption.</span></p><p class="c2"><span>Some good advice for VR testing app: User Evaluation</span><span><a class="c16" href="https://www.google.com/url?q=https://learn.gold.ac.uk/mod/helixmedia/view.php?id%3D606986%26forceview%3D1&amp;sa=D&amp;ust=1554252556670000">&nbsp;</a></span><span class="c14"><a class="c16" href="https://www.google.com/url?q=https://learn.gold.ac.uk/mod/helixmedia/view.php?id%3D606986%26forceview%3D1&amp;sa=D&amp;ust=1554252556670000">https://learn.gold.ac.uk/mod/helixmedia/view.php?id=606986&amp;forceview=1</a></span></p><p class="c2"><span class="c1">&nbsp;</span></p><p class="c2"><span class="c10">The rest of videos are non-theory based, just advice.</span></p><p class="c2 c4"><span class="c1"></span></p><div><p class="c4 c22"><span class="c1"></span></p></div></body></html>
